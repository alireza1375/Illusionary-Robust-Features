{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9FMIbf-UVgGG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from autoattack1 import AutoAttack\n",
        "from resnet import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULZ0swBuVgGI"
      },
      "outputs": [],
      "source": [
        "#In the first step we trained a model with standard (model), robust (model_r) and pure robust dataset (model_rr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S_sclv6VgGJ",
        "outputId": "6de144b4-0aac-45c0-e1ad-39f452bd2e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Load CIFAR-10 Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Step 2: Define Data Loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
        "# Step 3: Initialize ResNet Model\n",
        "model = ResNet50()\n",
        "\n",
        "# Step 4: Define Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Step 5: Training Loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Step 6: Validation/Test Loop\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Accuracy: {100 * accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2vZQLzVgGL"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'resnet50_cifar10.pt')\n",
        "\n",
        "print('Trained model saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the same for robust and pure robust model"
      ],
      "metadata": {
        "id": "1GjUDL3TW07B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzdLFTDHVgGM"
      },
      "outputs": [],
      "source": [
        "data_dir = './data'\n",
        "norm = 'L2'\n",
        "epsilon = 0.5\n",
        "model_path = './resnet50_cifar10.pt'\n",
        "n_ex = 10000\n",
        "individual = False\n",
        "save_dir = './results'\n",
        "batch_size = 500\n",
        "log_path = './log_file.txt'\n",
        "version = 'standard'\n",
        "state_path = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZk00PMJVgGM"
      },
      "outputs": [],
      "source": [
        "#Perturbing images assuming the adversary has complete knowledge of the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your model\n",
        "model = ResNet50()\n",
        "ckpt = torch.load(model_path)\n",
        "model.load_state_dict(ckpt)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# Load data\n",
        "transform_list = [transforms.ToTensor()]\n",
        "transform_chain = transforms.Compose(transform_list)\n",
        "item = datasets.CIFAR10(root=data_dir, train=False, transform=transform_chain, download=True)\n",
        "test_loader = torch.utils.data.DataLoader(item, batch_size=1000, shuffle=False, num_workers=0)\n",
        "\n",
        "# Create save directory\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Load attack\n",
        "adversary = AutoAttack(model, norm=norm, eps=epsilon, log_path=log_path, version=version)\n",
        "\n",
        "l = [x for (x, y) in test_loader]\n",
        "x_test = torch.cat(l, 0)\n",
        "l = [y for (x, y) in test_loader]\n",
        "y_test = torch.cat(l, 0)\n",
        "\n",
        "# Example of custom version\n",
        "if version == 'custom':\n",
        "    adversary.attacks_to_run = ['apgd-ce', 'fab']\n",
        "    adversary.apgd.n_restarts = 2\n",
        "    adversary.fab.n_restarts = 2\n",
        "\n",
        "# Run attack and save images\n",
        "with torch.no_grad():\n",
        "    if not individual:\n",
        "        adv_complete = adversary.run_standard_evaluation(x_test[:n_ex], y_test[:n_ex], bs=batch_size, state_path=state_path)\n",
        "\n",
        "        torch.save({'adv_complete': adv_complete}, f'{save_dir}/aa_{version}_1_{n_ex}_eps_{epsilon:.5f}-nr.pth')\n",
        "\n",
        "    else:\n",
        "        # Individual version, each attack is run on all test points\n",
        "        adv_complete = adversary.run_standard_evaluation_individual(x_test[:n_ex], y_test[:n_ex], bs=batch_size)\n",
        "\n",
        "        torch.save(adv_complete, f'{save_dir}/aa_{version}_individual_1_{n_ex}_eps_{epsilon:.5f}-nr.pth')"
      ],
      "metadata": {
        "id": "EYJ5gNAbWRlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQiBBrPxVgGO"
      },
      "outputs": [],
      "source": [
        "# Load saved data\n",
        "saved_data_path = f'{save_dir}/aa_{version}_1_{n_ex}_eps_{epsilon:.5f}-nr.pth'\n",
        "loaded_data = torch.load(saved_data_path)\n",
        "\n",
        "# Access the loaded data\n",
        "adv_complete_loaded_nr = loaded_data['adv_complete']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW6S2O0BVgGP"
      },
      "outputs": [],
      "source": [
        "#now give the perturbed images with robust auto attack to standard model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBZvUkEVgGQ",
        "outputId": "16b9e0d9-7685-4895-90a0-c9e3231480c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Accuracy on Adversarial Examples: 36.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "model = ResNet50()\n",
        "model.load_state_dict(torch.load('resnet50_cifar10.pt'))\n",
        "model.eval()\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "cifar10_test = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(cifar10_test, batch_size=1, shuffle=False)\n",
        "\n",
        "adv_labels = cifar10_test.targets[:10000]\n",
        "\n",
        "# Evaluate on adversarial examples\n",
        "num_correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(1000):\n",
        "        random_index = torch.randint(len(test_loader.dataset), (1,)).item()\n",
        "        input_image, target = adv_complete_loaded_nr[random_index], adv_labels[random_index]\n",
        "        input_image = input_image.unsqueeze(0)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        # Check accuracy\n",
        "        if predicted.item() == target:\n",
        "            num_correct += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = num_correct / 1000\n",
        "print(\"Accuracy on Adversarial Examples: {:.2%}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "repeat the same experiment for standard, robust and purified robust dataset, models ans attacks"
      ],
      "metadata": {
        "id": "J3rYVtqyYOpY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "My Environment 5",
      "language": "python",
      "name": "my_environment5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}